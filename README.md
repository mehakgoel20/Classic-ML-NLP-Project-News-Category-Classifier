# Classic-ML-NLP-Project-News-Category-Classifier
This project builds a news category classifier using classical NLP + ML techniques on a custom-engineered BBC News dataset. Starting with 42,000 raw RSS articles, I cleaned, deduplicated, and labeled the dataset using a custom URL-based category extraction pipeline, resulting in a high-quality 33,000-sample dataset across 8 categories.


ğŸ“° Project Overview

The final model uses TF-IDF + Linear SVM, achieving 86.6% accuracy, further improved through hyperparameter tuning with GridSearchCV.

ğŸš€ Key Features

âœ”ï¸ Engineered a 42k â†’ 33k curated BBC dataset
âœ”ï¸ Built custom URL-based label extraction (world, politics, sport, business, etc.)
âœ”ï¸ Text preprocessing using tokenization, cleaning, stopword removal, lemmatization (spaCy)
âœ”ï¸ Implemented and compared Naive Bayes, Logistic Regression, Linear SVM
âœ”ï¸ Achieved 86.6% test accuracy with LinearSVC
âœ”ï¸ Applied GridSearchCV for hyperparameter tuning
âœ”ï¸ Visualized performance using confusion matrix
âœ”ï¸ Extracted top TF-IDF features for interpretability
âœ”ï¸ Built a scalable ML pipeline ready for deployment

ğŸ“‚ Dataset Description

Source: BBC RSS feeds
Initial size: 42,000 articles
Final size: 33,000 cleaned and labeled samples

Columns used:
title
description
guid (link used for category extraction)
final_category (engineered label)
text (title + description merged + lemmatized)

Categories (after cleaning):

world
politics
business
sport
entertainment
technology
health
science

ğŸ§¹ Data Cleaning & Preprocessing

Removed duplicates and invalid rows
Dropped rows with missing category labels (None/misc)
Cleaned text: lowercasing, punctuation removal
Lemmatized using spaCy
Combined title + description into unified input text
ğŸ”§ Modeling Approach

1ï¸âƒ£ TF-IDF Vectorization

stop_words = "english"
max_features = 50,000
(1,1) and (1,2) n-grams tested

2ï¸âƒ£ Models Compared

Model	Accuracy
Naive Bayes	~76%
Logistic Regression	~84%
Linear SVM	86.6%
3ï¸âƒ£ GridSearchCV Tuning

Parameters tuned:

tfidf__max_features
tfidf__ngram_range
tfidf__min_df
tfidf__max_df
clf__C
clf__class_weight
Improved consistency and category-wise F1 performance.

ğŸ“Š Results

âœ”ï¸ Final Accuracy: 86.6%
âœ”ï¸ Best Model: LinearSVC
âœ”ï¸ Insights generated:
Confusion matrix heatmap
Top keywords per category (TF-IDF feature weights)
